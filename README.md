# :star:Recent Stars:star:


## SLAM
- [Bundle adjustment demo using Ceres Solver](https://github.com/izhengfan/ba_demo_ceres),  **[[Blog](https://fzheng.me/2018/01/23/ba-demo-ceres/)]**, ceres实现BA
- [CubeSLAM: Monocular 3D Object Detection and SLAM](https://github.com/shichaoy/cube_slam), **[[Paper](https://arxiv.org/abs/1806.00557)]**
- [PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud](https://github.com/sshaoshuai/PointRCNN), CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.04244)]**
- [GIST-Global Image Descriptor](https://github.com/nrupatunga/GIST-global-Image-Descripor), GIST描述子
- [mav voxblox planning](https://github.com/ethz-asl/mav_voxblox_planning), MAV planning tools using voxblox as the map representation.
- [Python Kalman Filter](https://github.com/zziz/kalman-filter), 30行实现卡尔曼滤波
- [vicalib](https://github.com/arpg/vicalib), 视觉惯导系统标定工具
- [BreezySLAM](https://github.com/simondlevy/BreezySLAM), 基于雷达的SLAM，支持Python(&Matlab, C++, and Java)
- [Probabilistic-Robotics](https://github.com/Yvon-Shong/Probabilistic-Robotics), 《概率机器人》中文版，书和课后习题
- [Stanford Self Driving Car Code](https://github.com/emmjaykay/stanford_self_driving_car_code), **[[Paper](http://robots.stanford.edu/papers/junior08.pdf)]**, 斯坦福自动驾驶车代码
- [Udacity Self-Driving Car Engineer Nanodegree projects](https://github.com/ndrplz/self-driving-car)
- [Artificial Intelligence in Automotive Technology](https://github.com/TUMFTM/Lecture_AI_in_Automotive_Technology), TUM自动驾驶技术中的人工智能课程
- [DeepMatchVO: Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation](https://github.com/hlzz/DeepMatchVO),ICRA 2019, **[[Paper](https://arxiv.org/abs/1902.09103)]**
- [GSLAM: A General SLAM Framework and Benchmark](https://github.com/zdzhaoyong/GSLAM), CVPR 2019, **[[Paper](https://arxiv.org/abs/1902.07995)]**, 集成了各种传感器输入的SLAM统一框架
- [Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints](https://github.com/izhengfan/se2lam)，ICRA 2019,基于SE(2)-XYZ约束的VO系统
- [Simple bag-of-words loop closure for visual SLAM](https://github.com/nicolov/simple_slam_loop_closure), **[[Blog](https://nicolovaligi.com/bag-of-words-loop-closure-visual-slam.html)]**, 回环
- [FBOW (Fast Bag of Words), an extremmely optimized version of the DBow2/DBow3 libraries](https://github.com/rmsalinas/fbow),优化版本的DBow2/DBow3
- [Multi-State Constraint Kalman Filter (MSCKF) for Vision-aided Inertial Navigation(master's thesis)](https://github.com/tomas789/tonav)
- [MSCKF](https://github.com/yuzhou42/MSCKF), MSCKF中文注释版
- [Calibration algorithm for a camera odometry system](https://github.com/hbtang/calibcamodo), VO系统的标定程序
- [Modified version of VINS-Mono](https://github.com/cggos/vins_mono_cg), 注释版本VINS Mono
- [Extreme Relative Pose Estimation for RGB-D Scans via Scene Completion](https://github.com/zhenpeiyang/RelativePose),**[[Paper](https://arxiv.org/abs/1901.00063)]**
- [Implementation of EPnP algorithm with Eigen](https://github.com/jessecw/EPnP_Eigen),利用Eigen编写的EPnP
- [Real-time SLAM system with deep features](https://github.com/jiexiong2016/GCNv2_SLAM), 深度学习描述子(ORB vs. GCNv2)
- [Unsupervised Learning of Monocular Depth Estimation and Visual Odometry with Deep Feature Reconstruction](https://github.com/Huangying-Zhan/Depth-VO-Feat), CVPR 2018, 无监督单目深度恢复以及VO
- [ORB-SLAM-windows](https://github.com/Phylliida/orbslam-windows), Windows版本的ORB-SLAM
- [StructVIO : Visual-inertial Odometry with Structural Regularity of Man-made Environments](https://github.com/danping/structvio),**[[Project Page](http://drone.sjtu.edu.cn/dpzou/project/structvio.html)]**
- [KalmanFiltering](https://github.com/irvingzhang/KalmanFiltering), 各种卡尔曼滤波器的demo
- [Stereo Odometry based on careful Feature selection and Tracking](https://github.com/ZhenghaoFei/visual_odom), **[[Paper](https://lamor.fer.hr/images/50020776/Cvisic2017.pdf)]**, C++ OpenCV实现SOFT
- [Visual SLAM with RGB-D Cameras based on Pose Graph Optimization](https://github.com/dzunigan/zSLAM)
- [Multi-threaded generic RANSAC implemetation](https://github.com/drsrinathsridhar/GRANSAC), 多线程RANSAC
- [Visual Odometry with Drift-Free Rotation Estimation Using Indoor Scene Regularities](https://github.com/PyojinKim/OPVO), BMVC 2017, **[[Project Page](http://pyojinkim.me/pub/Visual-Odometry-with-Drift-Free-Rotation-Estimation-Using-Indoor-Scene-Regularities/)]**，利用平面正交信息进行VO
- [ICE-BA](https://github.com/baidu/ICE-BA), CVPR 2018, **[[Paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.pdf)]**
- [GraphSfM: Robust and Efficient Graph-based Structure from Motion](https://github.com/AIBluefisher/GraphSfM), **[[Project Page](https://aibluefisher.github.io/GraphSfM/)]**
- [LOAM_NOTED](https://github.com/cuitaixiang/LOAM_NOTED), loam中文注解版


## Pose/Object tracking
- [Libra R-CNN: Towards Balanced Learning for Object Detection](https://github.com/OceanPang/Libra_R-CNN)
- [High-resolution networks (HRNets) for object detection](https://github.com/HRNet/HRNet-Object-Detection), **[[Paper](https://arxiv.org/pdf/1904.04514.pdf)]
- [Learning Correspondence from the Cycle-Consistency of Time](https://github.com/xiaolonw/TimeCycle), CVPR 2019, **[[Paper](https://arxiv.org/abs/1903.07593)]**
- [PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation](https://github.com/zju3dv/pvnet), CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.11788)], [[Project Page](https://zju3dv.github.io/pvnet)]**
- [Self-Supervised Learning of 3D Human Pose using Multi-view Geometry](https://github.com/mkocabas/EpipolarPose), CVPR 2018, **[[Paper](https://arxiv.org/abs/1903.02330)]**
- [PifPaf: Composite Fields for Human Pose Estimation](https://github.com/vita-epfl/openpifpaf), **[[Paper](https://arxiv.org/abs/1903.06593)]** 
- [Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch),CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09212.pdf)]**, **[[Project Page](https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html)]**
- [PoseFlow: Efficient Online Pose Tracking)](https://github.com/YuliangXiu/PoseFlow), BMVC 2018, **[[Paper](https://arxiv.org/abs/1802.00977)]**
- [A Bottom-Up Clustering Approach to Unsupervised Person Re-identification](https://github.com/vana77/Bottom-up-Clustering-Person-Re-identification)，AAAI 2019, 重定位
- [Fast Online Object Tracking and Segmentation: A Unifying Approach](https://github.com/foolwood/SiamMask),CVPR 2019,**[[Paper](https://arxiv.org/abs/1812.05050)] [[Video](https://youtu.be/I_iOVrcpEBw)] [[Project Page](http://www.robots.ox.ac.uk/~qwang/SiamMask)]**
- [SimpleDet - A Simple and Versatile Framework for Object Detection and Instance Recognition](https://github.com/TuSimple/simpledet),**[[Paper](https://arxiv.org/abs/1903.05831)]** 

## Depth/Disparity & Flow estimation 
- [Sparse Depth Completion](https://github.com/wvangansbeke/Sparse-Depth-Completion), **[[Paper](https://arxiv.org/pdf/1902.05356.pdf)]**, RGB图像辅助雷达深度估计
- [GASDA](https://github.com/sshan-zhao/GASDA), CVPR 2019, **[[Paper](https://sshan-zhao.github.io/papers/gasda.pdf)]**
- [MVSNet: Depth Inference for Unstructured Multi-view Stereo](https://github.com/xy-guo/MVSNet_pytorch), **[[Paper](https://arxiv.org/abs/1804.02505)]**, 非官方实现版本的MVSNet
- [Stereo R-CNN based 3D Object Detection for Autonomous Driving](https://github.com/HKUST-Aerial-Robotics/Stereo-RCNN), CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09738.pdf)]**
- [Real-time self-adaptive deep stereo](https://github.com/CVLAB-Unibo/Real-time-self-adaptive-deep-stereo), CVPR 2019, **[[Paper](https://arxiv.org/abs/1810.05424)]**
- [High Quality Monocular Depth Estimation via Transfer Learning](https://github.com/ialhashim/DenseDepth),CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.11941)]**, **[[Project Page](https://ialhashim.github.io/publications/index.html)]**
- [Group-wise Correlation Stereo Network](https://github.com/xy-guo/GwcNet),CVPR 2019, **[[Paper](https://arxiv.org/abs/1903.04025)]**
- [DeepMVS: Learning Multi-View Stereopsis](https://github.com/phuang17/DeepMVS), CVPR 2018,**[[Project Page](https://phuang17.github.io/DeepMVS/index.html)]**,多目深度估计
- [FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://github.com/sampepose/flownet2-tf), CVPR 2017, 深度学习光流恢复
- [StereoVision-ADCensus](https://github.com/DLuensch/StereoVision-ADCensus),深度恢复代码集合(**ADCensus, SGBM, BM**)
- [SegStereo: Exploiting Semantic Information for Disparity Estimation](https://github.com/yangguorun/SegStereo), 探究语义信息在深度估计中的作用
- [Light Filed Depth Estimation using GAN](https://github.com/kuantingchen04/Light-Field-Depth-Estimation)，利用GAN进行光场深度恢复
- [EV-FlowNet: Self-Supervised Optical Flow for Event-based Cameras](https://github.com/daniilidis-group/EV-FlowNet),Proceedings of Robotics 2018,**[[Paper](https://arxiv.org/abs/1802.06898)]**
- [DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency](https://github.com/vt-vl-lab/DF-Net), ECCV 2018, **[[Paper](https://arxiv.org/abs/1809.01649)]**
- [GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose](https://github.com/yzcjtr/GeoNet), CVPR 2018, **[[Paper](https://arxiv.org/abs/1803.02276)]** 

## 3D & Graphic
- [densebody_pytorch](https://github.com/Lotayou/densebody_pytorch), **[[Paper](https://arxiv.org/abs/1903.10153v3)]** 
- [Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding](https://github.com/svip-lab/PlanarReconstruction),CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09777.pdf)]**, 单目3D重建
- [HorizonNet: Learning Room Layout with 1D Representation and Pano Stretch Data Augmentation](https://github.com/sunset1995/HorizonNet),CVPR 2019, **[[Paper](https://arxiv.org/abs/1901.03861)]**, 深度学习全景转3D
- [Adaptive O-CNN: A Patch-based Deep Representation of 3D Shapes](https://github.com/Microsoft/O-CNN),SIGGRAPH Asia 2018, **[[Project Page](https://wang-ps.github.io/AO-CNN.html)]**


## GAN
- [End-to-end Adversarial Learning for Generative Conversational Agents](https://live.bilibili.com/7332534?visit_id=9ytrx9lpsy80)，2017，介绍了一种端到端的基于GAN的聊天机器人
- [Residual Non-local Attention Networks for Image Restoration](https://github.com/yulunzhang/RNAN),ICLR 2019.
- [MSGAN: Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis](https://github.com/HelenMao/MSGAN), CVPR 2019,**[[Paper](https://arxiv.org/abs/1903.05628)]**
- [SPADE: Semantic Image Synthesis with Spatially-Adaptive Normalization](https://github.com/NVlabs/SPADE),CVPR 2019, **[[Project Page](https://nvlabs.github.io/SPADE/)]**
- [Faceswap with Pytorch or DeepFake with Pytorch](https://github.com/Oldpan/Faceswap-Deepfake-Pytorch), 假脸


## Machine Learning
- [The best resources around Machine Learning](https://github.com/RemoteML/bestofml)
- [VGGFace2: A dataset for recognising faces across pose and age](https://github.com/cydonia999/VGGFace2-pytorch)
- [Statistical learning methods](https://github.com/SmirkCao/Lihang)


## Deep Learning
- [High-Performance Face Recognition Library on PyTorch](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)，人脸识别库
- [Deep-Learning-Coursera](https://github.com/enggen/Deep-Learning-Coursera)，深度学习教程（deeplearning.ai）
 
 

## Framework
- [Julia](https://github.com/JuliaLang/julia)
- [A Julia machine learning framework](https://github.com/alan-turing-institute/MLJ.jl)，一种基于Julia的机器学习框架

![](https://github.com/alan-turing-institute/MLJ.jl/blob/master/doc/two_model_stack.png)


## Collections
- [Segmentation.X](https://github.com/wutianyiRosun/Segmentation.X), 各种Segmentation论文&代码
- [CVPR-2019](https://github.com/amusi/CVPR2019-Code), CVPR 2019 论文开源项目合集
- [awesome-slam](https://github.com/kanster/awesome-slam), SLAM合集
- [awesome-visual-slam](https://github.com/tzutalin/awesome-visual-slam), 视觉SLAM合集
- [Papers with code](https://github.com/zziz/pwc), 周更论文with代码
- [Awesome Human Pose Estimation](https://github.com/cbsudux/awesome-human-pose-estimation),[awesome-object-pose](https://github.com/nkalavak/awesome-object-pose), 位姿估计合集
- [Awesome Semantic Segmentation](https://github.com/mrgloom/awesome-semantic-segmentation), 语义分割集合
- [IROS2018 SLAM Collections](https://github.com/mengyuest/iros2018-slam-papers), IROS 2018集合
- [VP-SLAM-SC-papers](https://github.com/TerenceCYJ/VP-SLAM-SC-papers),Visual Positioning & SLAM & Spatial Cognition 论文统计与分析
- [Awesome System for Machine Learning](https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning)
- [Machine-Learning-With-Python](https://github.com/Thinkgamer/Machine-Learning-With-Python), 《机器学习实战》python代码实现
- [How to learn robotics](https://github.com/qqfly/how-to-learn-robotics), 开源机器人学学习指南
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision),DL在CV领域的应用
- [Single-Image-Super-Resolution](https://github.com/YapengTian/Single-Image-Super-Resolution), 一个有关**图像超分辨**的合集
- [ai report](https://github.com/wifity/ai-report), AI相关的研究报告
- [State-of-the-art papers and code](https://paperswithcode.com/sota),搜集了目前sota的论文以及代码
- [CVPR 2019 (Papers/Codes/Project/Paper reading)](https://github.com/extreme-assistant/cvpr2019)
- [A curated list of papers & resources linked to 3D reconstruction from images](https://github.com/openMVG/awesome_3DReconstruction_list),有关三维重建的论文汇总
- [SLAM-Jobs](https://github.com/nebula-beta/SLAM-Jobs), SLAM/SFM求职指南

## Others
- [LPRNet: License Plate Recognition via Deep Neural Networks](https://github.com/lyl8213/Plate_Recognition-LPRnet), **[[Paper](https://arxiv.org/pdf/1806.10447.pdf)]** 
- [CHINESE-OCR](https://github.com/xiaofengShi/CHINESE-OCR), 运用tf实现自然场景文字检测
- [BeautyCamera](https://github.com/PerpetualSmile/BeautyCamera), 美颜相机，具有人脸检测、磨皮美白人脸、滤镜、调节图片、摄像功能
- [CV-arXiv-Daily](https://github.com/zhengzhugithub/CV-arXiv-Daily), 分享计算机视觉每天的arXiv文章
- Pluralistic-Inpainting, [ArXiv](https://arxiv.org/abs/1903.04227) | [Project Page](http://www.chuanxiaz.com/publication/pluralistic/) | [Online Demo](http://www.chuanxiaz.com/project/pluralistic/) | [Video(demo)](https://www.youtube.com/watch?v=9V7rNoLVmSs)
- [An Interactive Introduction to Fourier Transforms](https://github.com/Jezzamonn/fourier), 超棒的傅里叶变换图形化解释
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book), 《机器学习》（西瓜书）公式推导解析

## License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)

